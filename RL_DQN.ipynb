{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyNizV01djdAAoGtEqZx5Bjt"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"TsWZvqTjtLb0","executionInfo":{"status":"ok","timestamp":1762206748459,"user_tz":300,"elapsed":17906,"user":{"displayName":"Ciliang Chen","userId":"14395073300170304795"}},"outputId":"bf59c271-873f-4e86-df44-1ae6f1a07525"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["from google.colab import userdata\n","\n","%cd '/content/drive/MyDrive/Colab Notebooks/RL Final project/RL-final-group042'\n","\n","\n","!git config --global user.email \"chenciliang123@gmail.com\"\n","!git config --global user.name \"WhyIsItSoHardToFindANotUsedName\"\n","\n","token = userdata.get('TOKEN')\n","\n","!git add RL_DQN.ipynb\n","!git commit -m \"Added DQN\"\n","\n","!git push https://WhyIsItSoHardToFindANotUsedName:token@github.com/Yzhong9527/RL-final-group042.git main"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"vzMRXNNZrl43","executionInfo":{"status":"ok","timestamp":1762208509829,"user_tz":300,"elapsed":34770,"user":{"displayName":"Ciliang Chen","userId":"14395073300170304795"}},"outputId":"41749cdc-544d-407e-f291-b742df241e79"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stdout","text":["/content/drive/MyDrive/Colab Notebooks/RL Final project/RL-final-group042\n","fatal: cannot exec '.git/hooks/post-commit': Permission denied\n","[main 1253c88] Added DQN\n"," 1 file changed, 1 insertion(+), 1 deletion(-)\n"," rewrite RL_DQN.ipynb (97%)\n","remote: Invalid username or token. Password authentication is not supported for Git operations.\n","fatal: Authentication failed for 'https://github.com/Yzhong9527/RL-final-group042.git/'\n"]}]},{"cell_type":"code","source":["#SL:\n","import mne\n","import numpy as np\n","from sklearn.model_selection import train_test_split\n","import os\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","from torch.utils.data import DataLoader, TensorDataset\n","import time\n","\n","def preprocess(npz_file_path, test_size=0.15, val_size=0.176, random_state=42):\n","\n","    data = np.load(npz_file_path)\n","    print(f\" keys in file: {data.files}\")\n","\n","    s = data[\"s\"].T                 # convert to type (channels, samples)\n","    s = s[:22, :]                   # save 22 EEG channal, delete 3 others(EOG)\n","    etyp = data[\"etyp\"][:, 0]       # Convert to 1D ( events types )\n","    epos = data[\"epos\"][:, 0]       # Convert to 1D ( events positions)\n","\n","    print(f\"  EEG shape: {s.shape}\")\n","    print(f\"  events number: {len(etyp)}\")\n","\n","    mask = np.isin(etyp, [769, 770, 771, 772])\n","    task_events = etyp[mask]\n","    task_positions = epos[mask]\n","\n","    print(\" Event extraction completed\")\n","    print(f\"  Number of valid task events: {len(task_events)}\")\n","    print(f\"  The first few event types: {task_events[:10]}\")\n","\n","    fs = 250\n","    tmin, tmax = 0, 4\n","    n_samples = int((tmax - tmin) * fs)\n","\n","    trials, labels = [], []\n","\n","    for label, pos in zip(task_events, task_positions):\n","        start = int(pos + tmin * fs)\n","        end = start + n_samples\n","        if end <= s.shape[1]:                   # Preventing crossing the line\n","            trials.append(s[:, start:end])\n","            labels.append(label - 768)          # Mapping is 1~4\n","\n","    X = np.array(trials)\n","    y = np.array(labels)\n","\n","    print(\" Data segmentation completed\")\n","    print(f\"   X shape: {X.shape}\")\n","    print(f\"   y shape: {y.shape}\")\n","    print(f\"   labels type: {np.unique(y)}\")\n","\n","    ch_names = [f'EEG{i:03d}' for i in range(22)]\n","    ch_types = ['eeg'] * 22\n","    info = mne.create_info(ch_names=ch_names, sfreq=250, ch_types=ch_types)\n","\n","    epochs = mne.EpochsArray(X, info)                                                   # convert to type: (n_epochs, n_channels, n_samples)\n","    epochs_filtered = epochs.copy().filter(8, 30, method='fir', phase='zero-double')    # band-pass filtering\n","    X_filtered = epochs_filtered.get_data()\n","\n","    print(\" Filtering completed\")\n","    print(f\"   Data range before filtering: [{X.min():.3f}, {X.max():.3f}]\")\n","    print(f\"   Data range after  filtering: [{X_filtered.min():.3f}, {X_filtered.max():.3f}]\")\n","\n","    def remove_artifacts(X, y, threshold=100):\n","\n","        # Automatically detect and remove trials with abnormally large signal amplitudes (such as blinks, muscle electroencephalograms, and movement artifacts)\n","\n","        bad_epoch_indices = []\n","        print(f\"   Start artifact detection, threshold: {threshold} μV\")\n","\n","        for i in range(X.shape[0]):\n","            trial_data = X[i]\n","            if np.max(np.abs(trial_data)) > threshold:\n","                bad_epoch_indices.append(i)\n","\n","        print(f\"  {len(bad_epoch_indices)} trials contaminated by artifacts were found\")\n","\n","        if len(bad_epoch_indices) > 0:\n","            X_clean = np.delete(X, bad_epoch_indices, axis=0)\n","            y_clean = np.delete(y, bad_epoch_indices, axis=0)\n","        else:\n","            X_clean = X.copy()\n","            y_clean = y.copy()\n","\n","        print(f\"  {X_clean.shape[0]} clean trials are retained ({X_clean.shape[0]/X.shape[0]*100:.1f}%)\")\n","        return X_clean, y_clean\n","\n","    X_clean, y_clean = remove_artifacts(X_filtered, y, threshold=100)               # range: ± 100 μV\n","    print(\" Artifact removal completed\")\n","\n","    def standardize_data(X):\n","        print(\"   Start data normalization...\")\n","\n","        means = np.mean(X, axis=(0, 2), keepdims=True)\n","        stds = np.std(X, axis=(0, 2), keepdims=True)\n","        X_normalized = (X - means) / (stds + 1e-8)\n","\n","        print(f\"  Normalized data range: [{X_normalized.min():.3f}, {X_normalized.max():.3f}]\")\n","        return X_normalized\n","\n","    X_normalized = standardize_data(X_clean)\n","    print(\" Standardization completed\")\n","\n","    print(\" Start data partitioning...\")\n","\n","    X_train_val, X_test, y_train_val, y_test = train_test_split(\n","        X_normalized, y_clean,\n","        test_size=test_size,\n","        random_state=random_state,\n","        stratify=y_clean\n","    )\n","\n","    X_train, X_val, y_train, y_val = train_test_split(\n","        X_train_val, y_train_val,\n","        test_size=val_size,\n","        random_state=random_state,\n","        stratify=y_train_val\n","    )\n","\n","    print(\"Data partitioning completed！\")\n","    print(\"=\" * 50)\n","\n","    total_samples = len(X_normalized)\n","    train_ratio = len(X_train) / total_samples * 100\n","    val_ratio = len(X_val) / total_samples * 100\n","    test_ratio = len(X_test) / total_samples * 100\n","\n","    print(\"Final statistics:\")\n","    print(f\"  train: {X_train.shape} ({train_ratio:.1f}%)\")\n","    print(f\"  val: {X_val.shape} ({val_ratio:.1f}%)\")\n","    print(f\"  test: {X_test.shape} ({test_ratio:.1f}%)\")\n","\n","    print(f\"  Training set category distribution: {np.unique(y_train, return_counts=True)}\")\n","    print(f\"  Validation set category distribution: {np.unique(y_val, return_counts=True)}\")\n","    print(f\"  Testing set category distribution: {np.unique(y_test, return_counts=True)}\")\n","\n","    return X_train, X_val, X_test, y_train, y_val, y_test\n","\n","def data_augmentation(X, y):\n","\n","    \"\"\"\n","      When the original training samples are limited,\n","      we artificially create some reasonable \"variant\" samples to help the model learn more stable and generalizable features.\n","\n","    \"\"\"\n","\n","    print(\"Start data augmentation...\")\n","    augmented_X = []\n","    augmented_y = []\n","\n","    for i in range(X.shape[0]):\n","        augmented_X.append(X[i])\n","        augmented_y.append(y[i])\n","\n","        noise_std = 0.05                                        # Reduce noise intensity\n","        noise = np.random.normal(0, noise_std, X[i].shape)\n","        augmented_X.append(X[i] + noise)\n","        augmented_y.append(y[i])\n","\n","        if X.shape[2] > 100:\n","            shift = np.random.randint(-3, 4)                    # Reduce the offset range\n","            shifted = np.roll(X[i], shift, axis=1)\n","            if shift > 0:\n","                shifted[:, :shift] = 0\n","            elif shift < 0:\n","                shifted[:, shift:] = 0\n","            augmented_X.append(shifted)\n","            augmented_y.append(y[i])\n","\n","        scale_factor = np.random.uniform(0.9, 1.1)\n","        scaled = X[i] * scale_factor\n","        augmented_X.append(scaled)\n","        augmented_y.append(y[i])\n","\n","    augmented_X = np.array(augmented_X)\n","    augmented_y = np.array(augmented_y)\n","\n","    print(f\"Data enhancement completed: {X.shape[0]} -> {augmented_X.shape[0]} samples\")\n","    return augmented_X, augmented_y\n","\n","class ImprovedEEGNet(nn.Module):\n","    def __init__(self, num_classes=4, num_channels=22, sample_length=1000, dropout_rate=0.7):\n","        \"\"\"\n","        Improved EEGNet model\n","\n","        parameters:\n","        num_classes: Number of categories (default 4: left, right, foot, tongue)\n","        num_channels: Number of EEG channels (default 22)\n","        sample_length: Number of time points (default 1000)\n","        dropout_rate: dropout rate\n","\n","        \"\"\"\n","        super(ImprovedEEGNet, self).__init__()\n","\n","        \"\"\"\n","        Temporal Filtering:\n","\n","        Performing a 1D convolution on the time dimension is equivalent to extracting EEG temporal features (such as rhythm and frequency components).\n","\n","        Outputs 16 temporal filters.\n","\n","        \"\"\"\n","        self.temporal_filter = nn.Conv2d(\n","            in_channels=1,          # EEG data is viewed as a 2D image with 1 channel\n","            out_channels=16,\n","            kernel_size=(1, 64),\n","            padding=(0, 32),\n","            bias=False\n","        )\n","        self.batch_norm1 = nn.BatchNorm2d(16)\n","\n","        \"\"\"\n","\n","        Spatial Filtering:\n","\n","        Each temporal filter is then convolved along the channel dimension (kernel_size=(num_channels, 1)) to extract spatial features within the brain region.\n","\n","        groups=16 implements depthwise convolution (each temporal filter learns a separate spatial filter).\n","\n","        Output 32 channels (16×2)\n","\n","        \"\"\"\n","\n","        self.spatial_filter = nn.Conv2d(\n","            in_channels=16,\n","            out_channels=32,                # F1 * D = 16 * 2\n","            kernel_size=(num_channels, 1),\n","            groups=16,\n","            bias=False\n","        )\n","        self.batch_norm2 = nn.BatchNorm2d(32)\n","        self.activation1 = nn.ELU()\n","        self.avg_pool1 = nn.AvgPool2d(kernel_size=(1, 4))\n","        self.dropout1 = nn.Dropout(dropout_rate)\n","\n","        \"\"\"\n","\n","        Temporal Convolution + Pointwise Convolution:\n","\n","        Further extracting local dynamic features in the temporal dimension;\n","\n","        Using groups=32 to implement depthwise convolution, 1×1 convolution integrates different filters.\n","\n","        This is equivalent to the feature fusion layer.\n","\n","        \"\"\"\n","\n","        self.temporal_conv = nn.Conv2d(\n","            in_channels=32,\n","            out_channels=32,  # F2\n","            kernel_size=(1, 16),\n","            groups=32,\n","            padding=(0, 8),\n","            bias=False\n","        )\n","        self.conv_pointwise = nn.Conv2d(\n","            in_channels=32,\n","            out_channels=32,\n","            kernel_size=(1, 1),\n","            bias=False\n","        )\n","        self.batch_norm3 = nn.BatchNorm2d(32)\n","        self.activation2 = nn.ELU()\n","        self.avg_pool2 = nn.AvgPool2d(kernel_size=(1, 8))\n","        self.dropout2 = nn.Dropout(dropout_rate)\n","\n","        with torch.no_grad():\n","            sample_input = torch.randn(1, 1, num_channels, sample_length)\n","            sample_output = self._forward_features(sample_input)\n","            fc_input_size = sample_output.view(1, -1).size(1)\n","\n","        # Fully connected layer (classifier)\n","        self.classifier = nn.Sequential(\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(fc_input_size, 64),\n","            nn.ELU(),\n","            nn.Dropout(dropout_rate),\n","            nn.Linear(64, num_classes)\n","        )\n","\n","        print(f\"Fully connected layer input size: {fc_input_size}\")\n","\n","    def _forward_features(self, x):\n","\n","        # Feature extraction part of forward propagation\n","        x = self.temporal_filter(x)  # (batch, 16, channels, time)\n","        x = self.batch_norm1(x)\n","\n","        x = self.spatial_filter(x)   # (batch, 32, 1, time)\n","        x = self.batch_norm2(x)\n","        x = self.activation1(x)\n","        x = self.avg_pool1(x)\n","        x = self.dropout1(x)\n","\n","        x = self.temporal_conv(x)    # (batch, 32, 1, time')\n","        x = self.conv_pointwise(x)\n","        x = self.batch_norm3(x)\n","        x = self.activation2(x)\n","        x = self.avg_pool2(x)\n","        x = self.dropout2(x)\n","\n","        return x\n","\n","    def forward(self, x):\n","\n","        \"\"\"\n","\n","        Forward propagation\n","\n","        Parameters:\n","        x: Input data, shape (batch_size, 1, num_channels, sample_length)\n","\n","        \"\"\"\n","\n","        x = self._forward_features(x)\n","\n","        x = x.view(x.size(0), -1)\n","\n","        x = self.classifier(x)\n","\n","        return x\n","\n","    def predict_proba(self, x):\n","\n","        \"\"\"\n","\n","        Returns class probabilities\n","        Parameters:\n","        x: Input data, shape (batch_size, 1, num_channels, sample_length)\n","        Returns:\n","        probabilities: Probability matrix of shape (batch_size, 4)\n","\n","        \"\"\"\n","        self.eval()\n","        with torch.no_grad():\n","            output = self.forward(x)\n","            probabilities = F.softmax(output, dim=1)\n","            return probabilities.cpu().numpy()\n","\n","    def predict(self, x):\n","\n","        \"\"\"\n","\n","        Returns predicted labels (0-3)\n","        Parameters:\n","        x: Input data\n","        Returns:\n","        predictions: Predicted labels of shape (batch_size,)\n","\n","        \"\"\"\n","        self.eval()\n","        with torch.no_grad():\n","            output = self.forward(x)\n","            _, predicted = torch.max(output, 1)\n","            return predicted.cpu().numpy()\n","\n","def create_data_loaders(X_train, X_val, X_test, y_train, y_val, y_test, batch_size=32, use_augmentation=True):\n","\n","    \"\"\"\n","\n","    Create a PyTorch DataLoader\n","\n","    Parameters:\n","    X_train, X_val, X_test: Training, validation, and test data (numpy arrays)\n","    y_train, y_val, y_test: Corresponding labels (numpy arrays)\n","    batch_size: Batch size\n","    use_augmentation: Whether to use data augmentation\n","\n","    Returns:\n","    train_loader, val_loader, test_loader: Data loaders\n","\n","    \"\"\"\n","\n","    if use_augmentation:\n","        X_train_aug, y_train_aug = data_augmentation(X_train, y_train)\n","    else:\n","        X_train_aug, y_train_aug = X_train, y_train\n","\n","    X_train_tensor = torch.FloatTensor(X_train_aug).unsqueeze(1)\n","    X_val_tensor = torch.FloatTensor(X_val).unsqueeze(1)\n","    X_test_tensor = torch.FloatTensor(X_test).unsqueeze(1)\n","\n","    y_train_tensor = torch.LongTensor(y_train_aug - 1)\n","    y_val_tensor = torch.LongTensor(y_val - 1)\n","    y_test_tensor = torch.LongTensor(y_test - 1)\n","\n","    train_dataset = TensorDataset(X_train_tensor, y_train_tensor)\n","    val_dataset = TensorDataset(X_val_tensor, y_val_tensor)\n","    test_dataset = TensorDataset(X_test_tensor, y_test_tensor)\n","\n","    train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True)\n","    val_loader = DataLoader(val_dataset, batch_size=batch_size, shuffle=False)\n","    test_loader = DataLoader(test_dataset, batch_size=batch_size, shuffle=False)\n","\n","\n","\n","    print(f\"Data loader creation completed:\")\n","    print(f\"  train: {len(train_loader)} batches (增强后: {X_train_aug.shape[0]} 样本)\")\n","    print(f\"  val: {len(val_loader)} batches\")\n","    print(f\"  test: {len(test_loader)} batches\")\n","\n","    return train_loader, val_loader, test_loader\n","\n","def train_eegnet(model, train_loader, val_loader, num_epochs=200, learning_rate=1e-4, patience=15):\n","\n","    \"\"\"\n","\n","    Train an EEGNet model\n","\n","    Parameters:\n","    model: EEGNet model instance\n","    train_loader, val_loader: training and validation data loaders\n","    num_epochs: number of training epochs\n","    learning_rate: learning rate\n","    patience: early stopping patience value\n","\n","    \"\"\"\n","    if torch.cuda.is_available():\n","        device = torch.device(\"cuda\")\n","    elif torch.backends.mps.is_available():\n","        device = torch.device(\"mps\")\n","    else:\n","        device = torch.device(\"cpu\")\n","\n","    model = model.to(device)\n","\n","    criterion = nn.CrossEntropyLoss()\n","    optimizer = optim.AdamW(model.parameters(), lr=learning_rate, weight_decay=1e-3)\n","\n","    scheduler = optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='min', patience=8, factor=0.5)\n","\n","    train_losses = []\n","    val_losses = []\n","    train_accuracies = []\n","    val_accuracies = []\n","\n","    best_val_loss = float('inf')\n","    best_val_acc = 0.0\n","    patience_counter = 0\n","\n","    os.makedirs('./models', exist_ok=True)\n","    model_path = './models/best_eegnet_model.pth'\n","\n","    print(\"Start training...\")\n","    print(\"Epoch\\tTrain Loss\\tVal Loss\\tTrain Acc\\tVal Acc\\tBest Val Acc\\tLearning Rate\")\n","    print(\"-\" * 85)\n","\n","    start_time = time.time()\n","\n","    for epoch in range(num_epochs):\n","        model.train()\n","        train_loss = 0.0\n","        train_correct = 0\n","        train_total = 0\n","\n","        for batch_idx, (data, target) in enumerate(train_loader):\n","            data, target = data.to(device), target.to(device)\n","\n","            optimizer.zero_grad()\n","            output = model(data)\n","            loss = criterion(output, target)\n","            loss.backward()\n","\n","            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n","            optimizer.step()\n","\n","            train_loss += loss.item()\n","            _, predicted = torch.max(output.data, 1)\n","            train_total += target.size(0)\n","            train_correct += (predicted == target).sum().item()\n","\n","        train_loss /= len(train_loader)\n","        train_acc = 100. * train_correct / train_total\n","\n","        model.eval()\n","        val_loss = 0.0\n","        val_correct = 0\n","        val_total = 0\n","\n","        with torch.no_grad():\n","            for data, target in val_loader:\n","                data, target = data.to(device), target.to(device)\n","                output = model(data)\n","                val_loss += criterion(output, target).item()\n","\n","                _, predicted = torch.max(output.data, 1)\n","                val_total += target.size(0)\n","                val_correct += (predicted == target).sum().item()\n","\n","        val_loss /= len(val_loader)\n","        val_acc = 100. * val_correct / val_total\n","\n","        train_losses.append(train_loss)\n","        val_losses.append(val_loss)\n","        train_accuracies.append(train_acc)\n","        val_accuracies.append(val_acc)\n","\n","        scheduler.step(val_loss)\n","        current_lr = optimizer.param_groups[0]['lr']\n","\n","        if val_acc > best_val_acc:\n","            best_val_acc = val_acc\n","\n","        print(f\"{epoch+1:3d}\\t{train_loss:.4f}\\t\\t{val_loss:.4f}\\t\\t{train_acc:.2f}%\\t\\t{val_acc:.2f}%\\t\\t{best_val_acc:.2f}%\\t\\t{current_lr:.2e}\")\n","\n","        if val_loss < best_val_loss:\n","            best_val_loss = val_loss\n","            patience_counter = 0\n","            torch.save({\n","                'epoch': epoch,\n","                'model_state_dict': model.state_dict(),\n","                'optimizer_state_dict': optimizer.state_dict(),\n","                'val_loss': val_loss,\n","                'val_acc': val_acc,\n","                'best_val_acc': best_val_acc\n","            }, model_path)\n","            print(f\"      -> Save the best model (Verification accuracy: {val_acc:.2f}%)\")\n","        else:\n","            patience_counter += 1\n","            if patience_counter >= patience:\n","                print(f\"\\nEarly stopping: validation loss does not improve within {patience} epochs\")\n","                break\n","\n","    training_time = time.time() - start_time\n","    print(f\"Training complete! Total time: {training_time:.2f} seconds\")\n","\n","    checkpoint = torch.load(model_path)\n","    model.load_state_dict(checkpoint['model_state_dict'])\n","\n","    return {\n","        'model': model,\n","        'train_losses': train_losses,\n","        'val_losses': val_losses,\n","        'train_accuracies': train_accuracies,\n","        'val_accuracies': val_accuracies,\n","        'best_val_acc': best_val_acc,\n","        'training_time': training_time\n","    }\n","\n","def evaluate_model(model, test_loader):\n","\n","    device = next(model.parameters()).device\n","    model.eval()\n","\n","    test_correct = 0\n","    test_total = 0\n","    all_predictions = []\n","    all_targets = []\n","\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","            _, predicted = torch.max(output.data, 1)\n","\n","            test_total += target.size(0)\n","            test_correct += (predicted == target).sum().item()\n","\n","            all_predictions.extend(predicted.cpu().numpy())\n","            all_targets.extend(target.cpu().numpy())\n","\n","    test_acc = 100. * test_correct / test_total\n","\n","    print(\"\\n\" + \"=\" * 50)\n","    print(\"Model test results:\")\n","    print(f\"Test set accuracy: {test_acc:.2f}%\")\n","    print(\"=\" * 50)\n","\n","    return test_acc, all_predictions, all_targets\n","\n","def evaluate_model_with_probability(model, test_loader):\n","\n","    device = next(model.parameters()).device\n","    model.eval()\n","\n","    test_correct = 0\n","    test_total = 0\n","    all_probabilities = []\n","    all_predictions = []\n","    all_targets = []\n","\n","    with torch.no_grad():\n","        for data, target in test_loader:\n","            data, target = data.to(device), target.to(device)\n","            output = model(data)\n","\n","            # Add Softmax to get probability\n","            probabilities = F.softmax(output, dim=1)\n","            _, predicted = torch.max(output, 1)\n","\n","            test_total += target.size(0)\n","            test_correct += (predicted == target).sum().item()\n","\n","            all_probabilities.extend(probabilities.cpu().numpy())\n","            all_predictions.extend(predicted.cpu().numpy())\n","            all_targets.extend(target.cpu().numpy())\n","\n","    test_acc = 100. * test_correct / test_total\n","\n","    print(\"\\n\" + \"=\" * 50)\n","    print(\"Model test results (with probability output):\")\n","    print(f\"Test set accuracy: {test_acc:.2f}%\")\n","    print(f\"Probability output shape: {np.array(all_probabilities).shape}\")\n","    print(\"=\" * 50)\n","\n","    return test_acc, all_probabilities, all_predictions, all_targets\n","\n","\n","if __name__ == \"__main__\":\n","    print(\"=\" * 60)\n","    print(\"Start the complete SL decoder training process (improved version)\")\n","    print(\"=\" * 60)\n","\n","    print(\"\\nStep 1: Data Preprocessing\")\n","    X_train, X_val, X_test, y_train, y_val, y_test = preprocess(\n","        \"./bcidatasetIV2a-master/A01T.npz\"\n","    )\n","\n","    print(\"\\nStep 2: Create a data loader\")\n","    train_loader, val_loader, test_loader = create_data_loaders(\n","        X_train, X_val, X_test, y_train, y_val, y_test,\n","        batch_size=32, use_augmentation=True\n","    )\n","\n","    print(\"\\nStep 3: Create and improve the EEGNet model\")\n","    model = ImprovedEEGNet(\n","        num_classes=4,\n","        num_channels=22,\n","        sample_length=1000,\n","        dropout_rate=0.7                    # Add dropout to prevent overfitting\n","    )\n","\n","    test_input = torch.randn(2, 1, 22, 1000)\n","    with torch.no_grad():\n","        test_output = model(test_input)\n","    print(f\"Model testing - Input: {test_input.shape}, Output: {test_output.shape}\")\n","\n","    print(\"\\nStep 4: Train the model\")\n","    history = train_eegnet(\n","        model, train_loader, val_loader,\n","        num_epochs=200,\n","        learning_rate=1e-4,\n","        patience=15\n","    )\n","\n","    print(\"\\nStep 5: Model Evaluation\")\n","    test_acc, probabilities, predictions, targets = evaluate_model_with_probability(model, test_loader)\n","\n","    #  Probability Analysis\n","    print(\"\\nStep 6: Probability Analysis\")\n","    print(\"Probability distribution of the first 5 samples:\")\n","    for i in range(min(5, len(probabilities))):\n","        print(f\"Sample {i+1}: true label = {targets[i]+1}, predicted label = {predictions[i]+1}\")\n","        print(f\"  Probability: class 1 = {probabilities[i][0]:.3f}, class 2 = {probabilities[i][1]:.3f}, \"\n","            f\"Category 3 = {probabilities[i][2]: .3f}, Category 4 = {probabilities[i][3]: .3f}\")\n","\n","    # Calculate the average confidence\n","    confidences = np.max(probabilities, axis=1)\n","    print(f\"\\nAverage prediction confidence: {np.mean(confidences):.3f}\")\n","\n","    # Save probability results\n","    np.savez('./models/test_predictions.npz',\n","            probabilities=probabilities,\n","            predictions=predictions,\n","            targets=targets,\n","            test_accuracy=test_acc)\n","    print(\"The probability results have been saved as './models/test_predictions.npz'\")\n","\n","    print(\"\\n\" + \"=\" * 60)\n","    print(\"SL decoder (improved EEGNet) training completed!\")\n","    print(f\"Final verification accuracy: {history['best_val_acc']:.2f}%\")\n","    print(f\"Test set accuracy: {test_acc:.2f}%\")\n","    print(\"The model has been saved as './models/best_eegnet_model.pth'\")\n","    print(\"=\" * 60)"],"metadata":{"id":"EnX9GwfkBxRo"},"execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"metadata":{"id":"5n16l5dG_kIU"},"outputs":[],"source":["import gymnasium as gym\n","from gymnasium import spaces\n","import numpy as np\n","import pygame\n","import matplotlib.pyplot as plt\n","import pickle\n","from typing import Dict, List, Tuple, Optional\n","import seaborn as sns\n","import random\n","import tensorflow as tf\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","import torch.optim as optim\n","import numpy as np\n","\n","import matplotlib.pyplot as plt\n","from IPython import display\n","\n","if torch.cuda.is_available():\n","  device = \"cuda\"\n","else:\n","  device = \"cpu\"\n","\n","class BCICursorEnv(gym.Env):\n","\n","    def __init__(self, grid_size=9, max_steps=12, use_sl_probs=True, use_sl_features=False, feature_dim=64):\n","        super().__init__()\n","        self.grid_size = grid_size\n","        self.max_steps = max_steps\n","\n","        # Observation: [pos(2) + goal(2) + probs(4 opt) + features(opt)]\n","        base_dim = 4 if use_sl_probs else 0\n","        feature_dim = feature_dim if use_sl_features else 0\n","        self.observation_dim = 4 + base_dim + feature_dim\n","\n","        self.observation_space = spaces.Box(\n","            low=-1, high=1, shape=(self.observation_dim,), dtype=np.float32\n","        )\n","        self.action_space = spaces.Discrete(4)  # up, down, left, right\n","\n","        self.use_sl_probs = use_sl_probs\n","        self.use_sl_features = use_sl_features\n","        self.feature_dim = feature_dim\n","\n","        self.reset()\n","\n","\n","    def reset(self, start=None, goal=None, sl_probs=None, sl_features=None, seed=None):\n","        if seed is not None:\n","            np.random.seed(seed)\n","\n","        center = self.grid_size // 2\n","        self.pos = np.array(start or [center, center])\n","        self.goal = np.array(goal or [np.random.randint(self.grid_size), np.random.randint(self.grid_size)])\n","        self.sl_probs = np.array(sl_probs or [0.25, 0.25, 0.25, 0.25])\n","        self.sl_features = np.array(sl_features or np.zeros(self.feature_dim))\n","        self.steps = 0\n","        self.prev_action = None\n","        self.wall_hits = 0\n","\n","        return self._get_obs()\n","\n","\n","    def _get_obs(self):\n","        obs = np.concatenate([\n","            self.pos / self.grid_size,\n","            self.goal / self.grid_size,\n","            self.sl_probs if self.use_sl_probs else [],\n","            self.sl_features if self.use_sl_features else []\n","        ])\n","        return obs.astype(np.float32)\n","\n","\n","    def step(self, action):\n","        move_dict = {0: [-1, 0], 1: [1, 0], 2: [0, -1], 3: [0, 1]}\n","        move = np.array(move_dict[action])\n","\n","        old_pos = self.pos.copy()\n","        prev_dist = np.linalg.norm(self.pos - self.goal)\n","\n","        # Update position\n","        self.pos = np.clip(self.pos + move, 0, self.grid_size - 1)\n","        new_dist = np.linalg.norm(self.pos - self.goal)\n","\n","        # Base reward: distance change normalized by grid size\n","        delta = (prev_dist - new_dist) / self.grid_size\n","        reward = 0.5 * delta - 0.01  # step penalty\n","\n","        # Wall collision penalty\n","        if np.array_equal(self.pos, old_pos):\n","            reward -= 0.05\n","            self.wall_hits += 1\n","\n","        # Smoothness penalty\n","        if self.prev_action is not None and action != self.prev_action:\n","            reward -= 0.02\n","        self.prev_action = action\n","\n","        # Goal reached reward\n","        done = np.array_equal(self.pos, self.goal) or self.steps >= self.max_steps\n","        if np.array_equal(self.pos, self.goal):\n","            reward += 1.0\n","\n","        self.steps += 1\n","        return self._get_obs(), reward, done, {}\n","\n","\n","    def render(self, mode=\"human\"):\n","        grid = np.zeros((self.grid_size, self.grid_size))\n","        grid[self.goal[0], self.goal[1]] = 0.8\n","        grid[self.pos[0], self.pos[1]] = 1.0\n","        plt.imshow(grid, cmap=\"coolwarm\", origin=\"lower\")\n","        plt.title(f\"Step: {self.steps} | Wall hits: {self.wall_hits}\")\n","        plt.axis(\"off\")\n","        plt.pause(0.1)\n","        plt.clf()\n","\n","\n","\n","\n","\n"]},{"cell_type":"code","source":["class DuelingQNetwork(nn.Module):\n","    \"\"\"\n","    Clean implementation of Dueling DQN.\n","    Compatible with typical QNetwork(state_dim, action_dim, hidden_dim).\n","    \"\"\"\n","    def __init__(self, state_dim, action_dim, hidden_dim=128):\n","        super(DuelingQNetwork, self).__init__()\n","        self.feature = nn.Sequential(\n","            nn.Linear(state_dim, hidden_dim),\n","            nn.ReLU()\n","        )\n","        self.value_stream = nn.Sequential(\n","            nn.Linear(hidden_dim, hidden_dim),\n","            nn.ReLU(),\n","            nn.Linear(hidden_dim, 1)\n","        )\n","        self.advantage_stream = nn.Sequential(\n","            nn.Linear(hidden_dim, hidden_dim),\n","            nn.ReLU(),\n","            nn.Linear(hidden_dim, action_dim)\n","        )\n","    def forward(self, x):\n","        x = self.feature(x)\n","        value = self.value_stream(x)\n","        advantage = self.advantage_stream(x)\n","        q = value + (advantage - advantage.mean(dim=1, keepdim=True))\n","        return q"],"metadata":{"id":"Di8OUNTzr5ef"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","# --- Double DQN target helper ---\n","def compute_double_dqn_target(online_net, target_net, next_states, rewards, dones, gamma):\n","    # online_net: selects actions, target_net: provides Q-values for those actions\n","    with torch.no_grad():\n","        next_actions = online_net(next_states).argmax(1, keepdim=True)  # shape (batch, 1)\n","        next_q_target = target_net(next_states).gather(1, next_actions).squeeze(1)\n","        target = rewards + gamma * (1 - dones) * next_q_target\n","    return target\n","# Usage example in training loop:\n","# target_q = compute_double_dqn_target(q_net, target_net, next_state, reward, done, gamma)\n"],"metadata":{"id":"uUZA53T6sEdH"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def epsilon_greedy(q_net, state, epsilon, env):\n","  if random.random() < epsilon:\n","    return random.randrange(env.action_space.n)\n","  else:\n","    with torch.no_grad():\n","      q_values = q_net(torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0))\n","      action = int(torch.argmax(q_values))# select the best action determined by Q_table\n","      return action\n"],"metadata":{"id":"SEu0C7h3sKK1"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","from collections import deque\n","class ReplayBuffer:\n","  def __init__(self, capacity=5000):\n","        self.buffer = deque(maxlen=capacity)\n","\n","  def push(self, state, action, reward, next_state, done):\n","        self.buffer.append((state, action, reward, next_state, done))\n","\n","  def sample(self, batch_size):\n","      batch = random.sample(self.buffer, batch_size)\n","      states, actions, rewards, next_states, dones = zip(*batch)\n","      return (np.array(states, dtype=np.float32), np.array(actions), np.array(rewards, dtype=np.float32), np.array(next_states, dtype=np.float32), np.array(dones, dtype=np.float32))#keep them in float 32 to increase performance\n","\n","  def __len__(self):\n","      return len(self.buffer)"],"metadata":{"id":"w-gvYukfsTwF"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["def update_Q_network_double_dqn(q_net, target_q_net, optimizer, state, action, reward, next_state, done, gamma):\n","    state_t = torch.tensor(np.array(state), dtype=torch.float32, device=device)\n","    next_state_t = torch.tensor(np.array(next_state), dtype=torch.float32, device=device)\n","    action_t = torch.tensor(np.array(action), device=device)\n","    reward_t = torch.tensor(np.array(reward), dtype=torch.float32, device=device)\n","    done_t = torch.tensor(np.array(done), dtype=torch.float32, device=device)\n","\n","    # Double DQN\n","    with torch.no_grad():\n","        next_actions = q_net(next_state_t).argmax(1, keepdim=True)\n","        next_q_value = target_q_net(next_state_t).gather(1, next_actions).squeeze(1)\n","        target = reward_t + (gamma * next_q_value * (1 - done_t))\n","\n","    q_values = q_net(state_t)\n","    q_value = q_values.gather(1, action_t.unsqueeze(1))\n","    q_value = q_value.squeeze(1)\n","\n","    loss = F.mse_loss(q_value, target)\n","\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()"],"metadata":{"id":"82BvAnPmsWJ2"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["\n","def DQN(env, num_episodes:int =10000, gamma=0.9, lr = 0.00001, epsilon_decay=0.9954, epsilon_min = 0.01, max_step = 100, batch_size = 128, mode_name=\"SL+RL\"):\n","\n","    if isinstance(env.reset(), tuple):\n","        obs, _ = env.reset()\n","    else:\n","        obs = env.reset()\n","    state_size = np.prod(obs.shape)\n","    action_size = env.action_space.n\n","\n","    if hasattr(env, \"use_sl_features\") and env.use_sl_features:\n","        if layer is None:\n","            layer = 256\n","        print(\"Using Hybrid\")\n","    else:\n","        if layer is None:\n","            layer = 128\n","        print(\"Using SL+RL\")\n","\n","    q_net = DuelingQNetwork(state_size, action_size, layer).to(device)\n","    target_net = DuelingQNetwork(state_size, action_size, layer).to(device)\n","    target_net.load_state_dict(q_net.state_dict())  # initial sync\n","\n","    optimizer = optim.Adam(q_net.parameters(), lr = lr)\n","    replay_buffer = ReplayBuffer()\n","\n","    epsilon = 1.0\n","    epsilons = []\n","    rewards_per_episode = []\n","    count = 0\n","\n","    for episodes in range(num_episodes):\n","        if isinstance(env.reset(), tuple):\n","            obs, _ = env.reset()\n","        else:\n","            obs = env.reset()\n","        state = np.array(obs)\n","        total_reward = 0\n","        steps = 0\n","        terminated = False\n","        truncated = False\n","\n","        while not terminated and steps < max_step:\n","            action = epsilon_greedy(q_net, state, epsilon, env)\n","            next_obs, reward, terminated, truncated, info = env.step(action)\n","            next_state = np.array(next_obs, dtype=np.float32)\n","            done = terminated or truncated\n","\n","            # push to replay buffer\n","            replay_buffer.push(state, action, reward, next_state, done)\n","\n","            if (steps + 1) % 10 == 0: # update every 10 steps\n","                # update Q-net\n","                if len(replay_buffer) > batch_size:\n","                    batch = replay_buffer.sample(batch_size)\n","\n","                    update_Q_network_double_dqn(q_net, target_net, optimizer, *batch, gamma)\n","\n","            state = next_state\n","            steps += 1\n","            total_reward += reward\n","            if terminated or truncated:\n","                break\n","\n","        epsilon = max(epsilon_min, epsilon * epsilon_decay)\n","        epsilons.append(epsilon)\n","        rewards_per_episode.append(total_reward)\n","\n","        if (episodes + 1) % 5 == 0: # sync every 5 episode\n","            target_net.load_state_dict(q_net.state_dict())\n","        count += 1\n","\n","\n","    model_path = f\"final_assignment_ddqn_{mode_name}_YuanshanZhong_CiliangChen.pth\"\n","    torch.save(q_net.state_dict(), model_path)\n","    print(f\"Model weights saved to {model_path}\")\n","\n","\n","    num_eval_episodes = 20\n","    greedy_rewards_per_episode = []\n","    step_counts = []\n","\n","    print(f\"\\n--- Final Evaluation ({mode_name}, {num_eval_episodes} episodes) ---\")\n","    for eval_episode in range(num_eval_episodes):\n","        if isinstance(env.reset(), tuple):\n","            obs, _ = env.reset()\n","        else:\n","            obs = env.reset()\n","        state = np.array(obs)\n","        total_reward = 0\n","        steps = 0\n","        terminated = False\n","        truncated = False\n","\n","        while not terminated and steps < max_step:\n","            with torch.no_grad():\n","                q_values = q_net(torch.tensor(state, dtype=torch.float32, device=device).unsqueeze(0))\n","                action = int(torch.argmax(q_values))\n","\n","            next_obs, reward, terminated, truncated, info = env.step(action)\n","            next_state = np.array(next_obs, dtype=np.float32)\n","            state = next_state\n","            steps += 1\n","            total_reward += reward\n","            if terminated or truncated:\n","                break\n","\n","        greedy_rewards_per_episode.append(total_reward)\n","        step_counts.append(steps)\n","        print(f\"Episode {eval_episode+1}: Reward = {total_reward}, Steps = {steps}\")\n","\n","\n","    avg_reward = np.mean(greedy_rewards_per_episode)\n","    std_reward = np.std(greedy_rewards_per_episode)\n","    success_rate = len([r for r in greedy_rewards_per_episode if r > 0]) / len(greedy_rewards_per_episode)\n","\n","    print(f\"\\nEvaluation Summary for {mode_name}:\")\n","    print(f\"Average Reward: {avg_reward:.2f} ± {std_reward:.2f}\")\n","    print(f\"Success Rate: {success_rate:.2%}\")\n","    print(f\"Average Steps: {np.mean(step_counts):.2f}\")\n","\n","\n","    plt.figure(figsize=(18, 4))\n","\n","    plt.subplot(1, 4, 1)\n","    plt.plot(rewards_per_episode)\n","    plt.title(f\"{mode_name} - Training Episode Rewards\")\n","    plt.xlabel(\"Episode\")\n","    plt.ylabel(\"Total Reward\")\n","\n","    plt.subplot(1, 4, 2)\n","    plt.plot(epsilons)\n","    plt.title(f\"{mode_name} - Epsilon Decay\")\n","    plt.xlabel(\"Episode\")\n","    plt.ylabel(\"Epsilon\")\n","    plt.grid(True, alpha=0.3)\n","\n","\n","    plt.subplot(1, 4, 3)\n","    plt.plot(range(1, num_eval_episodes + 1), greedy_rewards_per_episode, marker='o', linewidth=2, markersize=4)\n","    plt.axhline(y=avg_reward, color='r', linestyle='--', linewidth=2,\n","                label=f'Average: {avg_reward:.2f} ± {std_reward:.2f}')\n","    plt.title(f\"{mode_name} - Greedy Policy Evaluation\\n({num_eval_episodes} episodes)\")\n","    plt.xlabel(\"Evaluation Episode\")\n","    plt.ylabel(\"Total Reward\")\n","    plt.legend()\n","    plt.grid(True, alpha=0.3)\n","\n","\n","    plt.subplot(1, 4, 4)\n","    plt.hist(greedy_rewards_per_episode, bins=10, alpha=0.7, edgecolor='black')\n","    plt.axvline(x=avg_reward, color='r', linestyle='--', linewidth=2,\n","                label=f'Mean: {avg_reward:.2f}')\n","    plt.title(f\"{mode_name} - Reward Distribution\")\n","    plt.xlabel(\"Total Reward\")\n","    plt.ylabel(\"Frequency\")\n","    plt.legend()\n","    plt.grid(True, alpha=0.3)\n","\n","    plt.tight_layout()\n","    plt.show()\n","\n","\n","    print(f\"\\nDetailed Evaluation Statistics for {mode_name}:\")\n","    print(f\"Min Reward: {np.min(greedy_rewards_per_episode):.2f}\")\n","    print(f\"Max Reward: {np.max(greedy_rewards_per_episode):.2f}\")\n","    print(f\"Median Reward: {np.median(greedy_rewards_per_episode):.2f}\")\n","    print(f\"Reward Range: {np.ptp(greedy_rewards_per_episode):.2f}\")\n","\n","    return q_net, epsilons, greedy_rewards_per_episode"],"metadata":{"id":"7k4rRq4DsZfM"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":["# 9 input, probablity of four direction and a token finding SL+RL or hybrid"],"metadata":{"id":"tBGURMkKkS8d"},"execution_count":null,"outputs":[]}]}